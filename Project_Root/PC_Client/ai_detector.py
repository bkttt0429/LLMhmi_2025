import cv2
import time
import numpy as np
import torch

# å˜—è©¦åŒ¯å…¥ YOLO
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    print("âš ï¸ è­¦å‘Š: æœªå®‰è£ ultralyticsã€‚è«‹åŸ·è¡Œ 'pip install ultralytics'")
    YOLO_AVAILABLE = False

class ObjectDetector:
    def __init__(self, model_path='yolov13s.pt'):
        self.model = None
        self.enabled = False
        
        # === è£ç½®é¸æ“‡ (GPU å„ªå…ˆ) ===
        if torch.cuda.is_available():
            self.device = 'cuda'
            print(f"ğŸš€ AI Device: NVIDIA CUDA ({torch.cuda.get_device_name(0)})")
        elif torch.backends.mps.is_available():
            self.device = 'mps'
            print("ğŸš€ AI Device: Apple MPS")
        else:
            self.device = 'cpu'
            print("âš ï¸ AI Device: CPU")

        # === æ§åˆ¶åƒæ•¸ ===
        self.base_v = 0.6
        self.max_w = 2.0
        self.conf_th = 0.4
        self.target_class = None 

        if YOLO_AVAILABLE:
            print(f"[AI] å˜—è©¦è¼‰å…¥æ¨¡å‹: {model_path}...")
            try:
                self.model = YOLO(model_path)
                print(f"[AI] {model_path} è¼‰å…¥æˆåŠŸã€‚")
                self.enabled = True
            except Exception as e:
                print(f"[AI] {model_path} è¼‰å…¥å¤±æ•—: {e}")
                print("[AI] å˜—è©¦é™ç´šä½¿ç”¨ yolov8n.pt (è‡ªå‹•ä¸‹è¼‰)...")
                try:
                    self.model = YOLO('yolov8n.pt')
                    self.enabled = True
                    print("[AI] yolov8n.pt è¼‰å…¥æˆåŠŸã€‚")
                except Exception as e2:
                    print(f"[AI] åš´é‡éŒ¯èª¤ï¼šç„¡æ³•è¼‰å…¥ä»»ä½•æ¨¡å‹ ({e2})")

    def decide_control(self, result, img_w, img_h):
        """è¨ˆç®—è‡ªå‹•é§•é§›æ§åˆ¶é‡ (v, w)"""
        boxes = result.boxes
        if boxes is None or len(boxes) == 0:
            return 0.0, 0.0

        # å–å¾— numpy array (å¦‚æœæ˜¯åœ¨ GPU ä¸Šï¼Œå…ˆè½‰ CPU)
        xyxy = boxes.xyxy.cpu().numpy()
        cls = boxes.cls.cpu().numpy()
        conf = boxes.conf.cpu().numpy()

        best_box = None
        best_score = -1

        for (x1, y1, x2, y2), c, s in zip(xyxy, cls, conf):
            if s < self.conf_th: continue
            if self.target_class is not None and int(c) != self.target_class: continue

            area = (x2 - x1) * (y2 - y1)
            if area > best_score:
                best_score = area
                best_box = (x1, y1, x2, y2)

        if best_box is None:
            return 0.0, 0.0

        x1, y1, x2, y2 = best_box
        cx = 0.5 * (x1 + x2)
        h = y2 - y1

        x_offset = (cx - img_w / 2) / (img_w / 2)
        size_ratio = h / img_h

        w = x_offset * self.max_w
        v = self.base_v * max(0.0, 1.0 - size_ratio)
        if size_ratio > 0.6: v = 0.0

        return v, w

    def detect(self, frame):
        """
        æ ¸å¿ƒåµæ¸¬æ–¹æ³•
        å›å‚³: (annotated_frame, detections_list, (v, w))
        """
        # é˜²å‘†ï¼šå¦‚æœæ²’å•Ÿç”¨æˆ–æ²’æ¨¡å‹ï¼ŒåŸåœ–å¥‰é‚„
        if not self.enabled or self.model is None:
            return frame, [], (0.0, 0.0)

        start_time = time.time()
        h, w_img = frame.shape[:2]
        
        # 1. æ¨è«– (Track æ¨¡å¼æ¯”è¼ƒç©©å®š)
        # persist=True èƒ½ä¿æŒ ID è¿½è¹¤ï¼Œå°å½±ç‰‡ä¸²æµå¾ˆé‡è¦
        results = self.model.track(frame, device=self.device, persist=True, conf=self.conf_th, verbose=False)
        result = results[0]
        
        # 2. ç¹ªåœ– (YOLO å…§å»ºç¹ªåœ–ï¼Œé€Ÿåº¦æœ€å¿«)
        annotated_frame = result.plot()
        
        # 3. è¨ˆç®—æ§åˆ¶
        v, ang_w = self.decide_control(result, w_img, h)

        # 4. æ•´ç†è³‡è¨Šåˆ—è¡¨
        detections = []
        if result.boxes:
            for box in result.boxes:
                try:
                    cls_id = int(box.cls[0])
                    # ç¢ºä¿ names å­—å…¸å­˜åœ¨
                    if hasattr(self.model, 'names'):
                        cls_name = self.model.names[cls_id]
                    else:
                        cls_name = str(cls_id)
                    detections.append({"class": cls_name})
                except: pass

        # 5. é¡¯ç¤ºè³‡è¨Š
        fps = 1.0 / (time.time() - start_time)
        info_text = f"FPS: {fps:.1f} | v={v:.2f} w={ang_w:.2f}"
        cv2.putText(annotated_frame, info_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        return annotated_frame, detections, (v, ang_w)